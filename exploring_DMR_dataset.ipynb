{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T11:07:16.675343Z",
     "start_time": "2025-09-14T11:07:16.659507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os"
   ],
   "id": "e1666ea61f925946",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T11:40:49.039822Z",
     "start_time": "2025-09-14T11:40:48.982813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to your data folder\n",
    "data_folder = r\"C:\\Users\\AGFirass\\PycharmProjects\\openDataParisDataScienceProject\\data\"\n",
    "\n",
    "# List CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(data_folder) if f.endswith(\".csv\")]\n",
    "\n",
    "columns_dict = {}\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(data_folder, file)\n",
    "    print(f\"Reading {file} ...\")\n",
    "\n",
    "    # Read header with correct encoding\n",
    "    df = pd.read_csv(file_path, sep=\";\", nrows=0, encoding=\"latin1\")\n",
    "\n",
    "    # Normalize column names: lowercase + strip spaces\n",
    "    normalized_columns = {col.strip().lower() for col in df.columns}\n",
    "    columns_dict[file] = normalized_columns\n",
    "\n",
    "# Get the union of all columns across files\n",
    "all_columns = set.union(*columns_dict.values())\n",
    "\n",
    "print(\"\\nðŸ”Ž Checking column name mismatches (case-insensitive):\\n\")\n",
    "for file, cols in columns_dict.items():\n",
    "    missing = all_columns - cols\n",
    "    extra = cols - all_columns\n",
    "    if missing or extra:\n",
    "        print(f\"{file} has column differences:\")\n",
    "        if missing:\n",
    "            print(f\"    Missing columns: {missing}\")\n",
    "        if extra:\n",
    "            print(f\"    Extra columns: {extra}\")\n",
    "    else:\n",
    "        print(f\"{file} âœ… matches all columns\")\n",
    "\n",
    "print(\"\\nâœ… Column comparison complete.\")"
   ],
   "id": "7ac0aeb41142580e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DMR_2018.csv ...\n",
      "Reading DMR_2019.csv ...\n",
      "Reading DMR_2020.csv ...\n",
      "Reading DMR_2021.csv ...\n",
      "Reading DMR_2022.csv ...\n",
      "Reading DMR_2023.csv ...\n",
      "\n",
      "ðŸ”Ž Checking column name mismatches (case-insensitive):\n",
      "\n",
      "DMR_2018.csv has column differences:\n",
      "    Missing columns: {'Ã¯Â»Â¿oid_', 'dateetat', 'etat'}\n",
      "DMR_2019.csv has column differences:\n",
      "    Missing columns: {'Ã¯Â»Â¿oid_', 'dateetat', 'etat'}\n",
      "DMR_2020.csv has column differences:\n",
      "    Missing columns: {'Ã¯Â»Â¿oid_', 'dateetat', 'etat'}\n",
      "DMR_2021.csv has column differences:\n",
      "    Missing columns: {'objectid'}\n",
      "DMR_2022.csv has column differences:\n",
      "    Missing columns: {'Ã¯Â»Â¿oid_', 'objectid'}\n",
      "DMR_2023.csv has column differences:\n",
      "    Missing columns: {'Ã¯Â»Â¿oid_', 'objectid'}\n",
      "\n",
      "âœ… Column comparison complete.\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T11:43:22.955229Z",
     "start_time": "2025-09-14T11:43:19.297403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file = r\"C:\\Users\\AGFirass\\PycharmProjects\\openDataParisDataScienceProject\\data\\DMR_2023.csv\"\n",
    "df23 = pd.read_csv(file, sep=\";\", encoding=\"latin1\")\n",
    "df23.head()"
   ],
   "id": "6ea118f33d2681ee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         id_dmr                     type  \\\n",
       "0  G2023E019075                 PropretÃ©   \n",
       "1  G2023B012260  Voirie et espace public   \n",
       "2  G2023B040779  Voirie et espace public   \n",
       "3  G2023B039734  Voirie et espace public   \n",
       "4  G2023C037699  Voirie et espace public   \n",
       "\n",
       "                                            soustype  \\\n",
       "0                           [] Renfort Fonctionnelle   \n",
       "1   Trottoirs : Affaissement, trou, bosse, pavÃ© a...   \n",
       "2   Trottoirs : Affaissement, trou, bosse, pavÃ© a...   \n",
       "3   Marquage au sol  effacÃ©  : Bande en relief po...   \n",
       "4   Trottoirs : Affaissement, trou, bosse, pavÃ© a...   \n",
       "\n",
       "                                     adresse  code_postal     ville  \\\n",
       "0            1 Rue des Panoyaux, 75020 PARIS      75020.0  Paris 20   \n",
       "1  51 boulevard des Batignolles, 75017 PARIS      75017.0  Paris 08   \n",
       "2      2 place Ferdinand Brunot, 75014 PARIS      75014.0  Paris 14   \n",
       "3         146 Rue VercingÃ©torix, 75014 PARIS      75014.0  Paris 14   \n",
       "4               34 Rue d'AlÃ©sia, 75014 PARIS      75014.0  Paris 14   \n",
       "\n",
       "   arrondissement          datedecl  anneedecl  moisdecl          etat  \\\n",
       "0              20  10/05/2023 00:00       2023         5  Service fait   \n",
       "1               8  05/02/2023 00:00       2023         2  Service fait   \n",
       "2              14  16/02/2023 00:00       2023         2  Service fait   \n",
       "3              14  15/02/2023 00:00       2023         2  Service fait   \n",
       "4              14  17/03/2023 00:00       2023         3  Service fait   \n",
       "\n",
       "           dateetat  numero prefixe             intervenant  \\\n",
       "0  12/05/2023 00:00   19075       G  DPE-STPP-Fonctionnelle   \n",
       "1  15/01/2024 00:00   12260       G                     DVD   \n",
       "2  15/01/2024 00:00   40779       G                     DVD   \n",
       "3  15/01/2024 00:00   39734       G                     DVD   \n",
       "4  15/01/2024 00:00   37699       G                     DVD   \n",
       "\n",
       "            conseilquartier          X           Y  \n",
       "0  AMANDIERS - MENILMONTANT  2,3843699  48,8662605  \n",
       "1                    MAIRIE  2,3186738  48,8814812  \n",
       "2         MOUTON - DUVERNET   2,326889  48,8331032  \n",
       "3   DIDOT - PORTE DE VANVES   2,311317  48,8327599  \n",
       "4         MOUTON - DUVERNET  2,3297775  48,8279572  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_dmr</th>\n",
       "      <th>type</th>\n",
       "      <th>soustype</th>\n",
       "      <th>adresse</th>\n",
       "      <th>code_postal</th>\n",
       "      <th>ville</th>\n",
       "      <th>arrondissement</th>\n",
       "      <th>datedecl</th>\n",
       "      <th>anneedecl</th>\n",
       "      <th>moisdecl</th>\n",
       "      <th>etat</th>\n",
       "      <th>dateetat</th>\n",
       "      <th>numero</th>\n",
       "      <th>prefixe</th>\n",
       "      <th>intervenant</th>\n",
       "      <th>conseilquartier</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G2023E019075</td>\n",
       "      <td>PropretÃ©</td>\n",
       "      <td>[] Renfort Fonctionnelle</td>\n",
       "      <td>1 Rue des Panoyaux, 75020 PARIS</td>\n",
       "      <td>75020.0</td>\n",
       "      <td>Paris 20</td>\n",
       "      <td>20</td>\n",
       "      <td>10/05/2023 00:00</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>Service fait</td>\n",
       "      <td>12/05/2023 00:00</td>\n",
       "      <td>19075</td>\n",
       "      <td>G</td>\n",
       "      <td>DPE-STPP-Fonctionnelle</td>\n",
       "      <td>AMANDIERS - MENILMONTANT</td>\n",
       "      <td>2,3843699</td>\n",
       "      <td>48,8662605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G2023B012260</td>\n",
       "      <td>Voirie et espace public</td>\n",
       "      <td>Trottoirs : Affaissement, trou, bosse, pavÃ© a...</td>\n",
       "      <td>51 boulevard des Batignolles, 75017 PARIS</td>\n",
       "      <td>75017.0</td>\n",
       "      <td>Paris 08</td>\n",
       "      <td>8</td>\n",
       "      <td>05/02/2023 00:00</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>Service fait</td>\n",
       "      <td>15/01/2024 00:00</td>\n",
       "      <td>12260</td>\n",
       "      <td>G</td>\n",
       "      <td>DVD</td>\n",
       "      <td>MAIRIE</td>\n",
       "      <td>2,3186738</td>\n",
       "      <td>48,8814812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G2023B040779</td>\n",
       "      <td>Voirie et espace public</td>\n",
       "      <td>Trottoirs : Affaissement, trou, bosse, pavÃ© a...</td>\n",
       "      <td>2 place Ferdinand Brunot, 75014 PARIS</td>\n",
       "      <td>75014.0</td>\n",
       "      <td>Paris 14</td>\n",
       "      <td>14</td>\n",
       "      <td>16/02/2023 00:00</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>Service fait</td>\n",
       "      <td>15/01/2024 00:00</td>\n",
       "      <td>40779</td>\n",
       "      <td>G</td>\n",
       "      <td>DVD</td>\n",
       "      <td>MOUTON - DUVERNET</td>\n",
       "      <td>2,326889</td>\n",
       "      <td>48,8331032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G2023B039734</td>\n",
       "      <td>Voirie et espace public</td>\n",
       "      <td>Marquage au sol  effacÃ©  : Bande en relief po...</td>\n",
       "      <td>146 Rue VercingÃ©torix, 75014 PARIS</td>\n",
       "      <td>75014.0</td>\n",
       "      <td>Paris 14</td>\n",
       "      <td>14</td>\n",
       "      <td>15/02/2023 00:00</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>Service fait</td>\n",
       "      <td>15/01/2024 00:00</td>\n",
       "      <td>39734</td>\n",
       "      <td>G</td>\n",
       "      <td>DVD</td>\n",
       "      <td>DIDOT - PORTE DE VANVES</td>\n",
       "      <td>2,311317</td>\n",
       "      <td>48,8327599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G2023C037699</td>\n",
       "      <td>Voirie et espace public</td>\n",
       "      <td>Trottoirs : Affaissement, trou, bosse, pavÃ© a...</td>\n",
       "      <td>34 Rue d'AlÃ©sia, 75014 PARIS</td>\n",
       "      <td>75014.0</td>\n",
       "      <td>Paris 14</td>\n",
       "      <td>14</td>\n",
       "      <td>17/03/2023 00:00</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>Service fait</td>\n",
       "      <td>15/01/2024 00:00</td>\n",
       "      <td>37699</td>\n",
       "      <td>G</td>\n",
       "      <td>DVD</td>\n",
       "      <td>MOUTON - DUVERNET</td>\n",
       "      <td>2,3297775</td>\n",
       "      <td>48,8279572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T11:43:50.901174Z",
     "start_time": "2025-09-14T11:43:50.888176Z"
    }
   },
   "cell_type": "code",
   "source": "df23.size",
   "id": "491da0fa78bf7b5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15533658"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T11:44:38.464157Z",
     "start_time": "2025-09-14T11:44:38.432882Z"
    }
   },
   "cell_type": "code",
   "source": "df23.anneedecl.unique()",
   "id": "47dd7180daf34061",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2023])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T21:13:07.318325Z",
     "start_time": "2025-09-14T21:12:35.523355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from functools import reduce\n",
    "import chardet\n",
    "\n",
    "# Define the data directory and file names\n",
    "data_dir = r\"C:\\Users\\AGFirass\\PycharmProjects\\openDataParisDataScienceProject\\data\"\n",
    "files = [\n",
    "    \"DMR_2018.csv\",\n",
    "    \"DMR_2019.csv\",\n",
    "    \"DMR_2020.csv\",\n",
    "    \"DMR_2021.csv\",\n",
    "    \"DMR_2022.csv\",\n",
    "    \"DMR_2023.csv\"\n",
    "]\n",
    "\n",
    "def detect_encoding(file_path):\n",
    "    \"\"\"Detect the encoding of a file\"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        raw_data = f.read(10000)  # Read first 10KB to detect encoding\n",
    "        result = chardet.detect(raw_data)\n",
    "        encoding = result['encoding']\n",
    "        confidence = result['confidence']\n",
    "        print(f\"Detected encoding for {os.path.basename(file_path)}: {encoding} (confidence: {confidence:.2f})\")\n",
    "        return encoding\n",
    "\n",
    "def read_csv_safe(file_path, sep=','):\n",
    "    \"\"\"Safely read CSV file with automatic encoding detection\"\"\"\n",
    "    try:\n",
    "        # First try UTF-8\n",
    "        return pd.read_csv(file_path, sep=sep, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        try:\n",
    "            # Try ISO-8859-1 (Latin-1) which is common for European languages\n",
    "            return pd.read_csv(file_path, sep=sep, encoding='iso-8859-1')\n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                # Try Windows-1252 (common for Windows systems)\n",
    "                return pd.read_csv(file_path, sep=sep, encoding='cp1252')\n",
    "            except UnicodeDecodeError:\n",
    "                # If all else fails, detect encoding automatically\n",
    "                encoding = detect_encoding(file_path)\n",
    "                return pd.read_csv(file_path, sep=sep, encoding=encoding)\n",
    "\n",
    "def find_common_columns(file_paths):\n",
    "    \"\"\"Find columns that are common to all CSV files\"\"\"\n",
    "    all_columns = []\n",
    "\n",
    "    # Read headers from each file\n",
    "    for file_path in file_paths:\n",
    "        df = read_csv_safe(file_path, sep=';')  # Read only headers\n",
    "        columns = set(df.columns)\n",
    "        all_columns.append(columns)\n",
    "        print(f\"{os.path.basename(file_path)}: {len(columns)} columns\")\n",
    "\n",
    "    # Find intersection of all column sets\n",
    "    common_columns = reduce(lambda x, y: x.intersection(y), all_columns)\n",
    "    print(f\"\\nCommon columns across all files: {len(common_columns)}\")\n",
    "    print(\"Common columns:\", sorted(list(common_columns)))\n",
    "\n",
    "    return list(common_columns)\n",
    "\n",
    "def merge_csv_files(file_paths, common_columns):\n",
    "    \"\"\"Merge CSV files using only common columns\"\"\"\n",
    "    dataframes = []\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        print(f\"Reading {os.path.basename(file_path)}...\")\n",
    "\n",
    "        # Read the full CSV file with safe encoding handling\n",
    "        df = read_csv_safe(file_path, sep=';')\n",
    "\n",
    "        # Convert all column names to lowercase\n",
    "        df.columns = df.columns.str.lower()\n",
    "\n",
    "        # Select only common columns (convert to lowercase for comparison)\n",
    "        available_columns = [col for col in common_columns if col in df.columns]\n",
    "        df = df[available_columns]\n",
    "\n",
    "        # Add a year column for identification\n",
    "        year = os.path.basename(file_path).split('_')[1].split('.')[0]\n",
    "        df['year'] = int(year)\n",
    "\n",
    "        dataframes.append(df)\n",
    "        print(f\"  Shape: {df.shape}\")\n",
    "\n",
    "    # Concatenate all dataframes\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "    print(f\"\\nMerged dataframe shape: {merged_df.shape}\")\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Create full file paths\n",
    "    file_paths = [os.path.join(data_dir, file) for file in files]\n",
    "\n",
    "    # Check if all files exist\n",
    "    missing_files = [f for f in file_paths if not os.path.exists(f)]\n",
    "    if missing_files:\n",
    "        print(\"Missing files:\")\n",
    "        for f in missing_files:\n",
    "            print(f\"  {f}\")\n",
    "        exit(1)\n",
    "\n",
    "    # Find common columns\n",
    "    common_columns = find_common_columns(file_paths)\n",
    "\n",
    "    if not common_columns:\n",
    "        print(\"No common columns found across all files!\")\n",
    "        exit(1)\n",
    "\n",
    "    # Convert common columns to lowercase for consistency\n",
    "    common_columns = [col.lower() for col in common_columns]\n",
    "\n",
    "    # Merge the files\n",
    "    merged_df = merge_csv_files(file_paths, common_columns)\n",
    "\n",
    "    # Display info about the merged dataframe\n",
    "    print(f\"\\nMerged dataframe info:\")\n",
    "    print(f\"Shape: {merged_df.shape}\")\n",
    "    print(f\"Columns: {list(merged_df.columns)}\")\n",
    "    print(f\"Year distribution:\")\n",
    "    print(merged_df['year'].value_counts().sort_index())\n",
    "\n",
    "    # Save the merged dataframe\n",
    "    output_file = os.path.join(data_dir, \"DMR_merged_2018_2023.csv\")\n",
    "    merged_df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    print(f\"\\nMerged data saved to: {output_file}\")\n",
    "\n",
    "    # Show sample of the data\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(merged_df.head())"
   ],
   "id": "9cfb6a4b011f3b39",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DMR_2018.csv: 17 columns\n",
      "DMR_2019.csv: 17 columns\n",
      "DMR_2020.csv: 17 columns\n",
      "DMR_2021.csv: 19 columns\n",
      "DMR_2022.csv: 18 columns\n",
      "DMR_2023.csv: 18 columns\n",
      "\n",
      "Common columns across all files: 2\n",
      "Common columns: ['X', 'Y']\n",
      "Reading DMR_2018.csv...\n",
      "  Shape: (251692, 3)\n",
      "Reading DMR_2019.csv...\n",
      "  Shape: (556643, 3)\n",
      "Reading DMR_2020.csv...\n",
      "  Shape: (586270, 3)\n",
      "Reading DMR_2021.csv...\n",
      "  Shape: (850304, 3)\n",
      "Reading DMR_2022.csv...\n",
      "  Shape: (846239, 3)\n",
      "Reading DMR_2023.csv...\n",
      "  Shape: (862981, 3)\n",
      "\n",
      "Merged dataframe shape: (3954129, 3)\n",
      "\n",
      "Merged dataframe info:\n",
      "Shape: (3954129, 3)\n",
      "Columns: ['y', 'x', 'year']\n",
      "Year distribution:\n",
      "year\n",
      "2018    251692\n",
      "2019    556643\n",
      "2020    586270\n",
      "2021    850304\n",
      "2022    846239\n",
      "2023    862981\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Merged data saved to: C:\\Users\\AGFirass\\PycharmProjects\\openDataParisDataScienceProject\\data\\DMR_merged_2018_2023.csv\n",
      "\n",
      "First few rows:\n",
      "             y            x  year\n",
      "0    48,881588  2,336608406  2018\n",
      "1  48,84168304  2,294903576  2018\n",
      "2  48,84117406  2,295035066  2018\n",
      "3     48,85348  2,368076605  2018\n",
      "4    48,887924  2,354395399  2018\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T21:15:56.207050Z",
     "start_time": "2025-09-14T21:15:48.117444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file20 = r\"C:\\Users\\AGFirass\\PycharmProjects\\openDataParisDataScienceProject\\data\\DMR_2020.csv\"\n",
    "df20 = pd.read_csv(file20, engine=\"python\", sep=\";\")\n",
    "df20.columns"
   ],
   "id": "ffd94364e4bac536",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OBJECTID', 'ID_DMR', 'TYPE', 'SOUSTYPE', 'ADRESSE', 'CODE_POSTAL',\n",
       "       'VILLE', 'ARRONDISSEMENT', 'DATEDECL', 'ANNEEDECL', 'MOISDECL',\n",
       "       'NUMERO', 'PREFIXE', 'INTERVENANT', 'CONSEILQUARTIER', 'X', 'Y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T21:16:48.909904Z",
     "start_time": "2025-09-14T21:16:36.432861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file21 = r\"C:\\Users\\AGFirass\\PycharmProjects\\openDataParisDataScienceProject\\data\\DMR_2021.csv\"\n",
    "df21 = pd.read_csv(file21, engine=\"python\", sep=\";\")\n",
    "df21.columns"
   ],
   "id": "4fe94581a8eb17c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OID_', 'ID_DMR', 'TYPE', 'SOUSTYPE', 'ADRESSE', 'CODE_POSTAL', 'VILLE',\n",
       "       'ARRONDISSEMENT', 'DATEDECL', 'ANNEEDECL', 'MOISDECL', 'ETAT',\n",
       "       'DATEETAT', 'NUMERO', 'PREFIXE', 'INTERVENANT', 'CONSEILQUARTIER', 'X',\n",
       "       'Y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T21:17:24.962863Z",
     "start_time": "2025-09-14T21:17:13.230100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file22 = r\"C:\\Users\\AGFirass\\PycharmProjects\\openDataParisDataScienceProject\\data\\DMR_2022.csv\"\n",
    "df22 = pd.read_csv(file22, engine=\"python\", sep=\";\", encoding='latin1')\n",
    "df22.columns"
   ],
   "id": "937c3aa6c1a55df7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_dmr', 'type', 'soustype', 'adresse', 'code_postal', 'ville',\n",
       "       'arrondissement', 'datedecl', 'anneedecl', 'moisdecl', 'etat',\n",
       "       'dateetat', 'numero', 'prefixe', 'intervenant', 'conseilquartier', 'X',\n",
       "       'Y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T21:17:58.202786Z",
     "start_time": "2025-09-14T21:17:47.230776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file23 = r\"C:\\Users\\AGFirass\\PycharmProjects\\openDataParisDataScienceProject\\data\\DMR_2023.csv\"\n",
    "df23 = pd.read_csv(file23, engine=\"python\", sep=\";\", encoding='latin1')\n",
    "df23.columns"
   ],
   "id": "e8ca0b5e6221d99e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_dmr', 'type', 'soustype', 'adresse', 'code_postal', 'ville',\n",
       "       'arrondissement', 'datedecl', 'anneedecl', 'moisdecl', 'etat',\n",
       "       'dateetat', 'numero', 'prefixe', 'intervenant', 'conseilquartier', 'X',\n",
       "       'Y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T21:26:13.642859Z",
     "start_time": "2025-09-14T21:25:28.024827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from functools import reduce\n",
    "import chardet\n",
    "\n",
    "def detect_encoding(file_path):\n",
    "    \"\"\"Detect the encoding of a file\"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        raw_data = f.read(10000)\n",
    "        result = chardet.detect(raw_data)\n",
    "        return result['encoding']\n",
    "\n",
    "def read_csv_safe(file_path, **kwargs):\n",
    "    \"\"\"Safely read CSV with encoding detection\"\"\"\n",
    "    encodings_to_try = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']\n",
    "\n",
    "    try:\n",
    "        detected_encoding = detect_encoding(file_path)\n",
    "        if detected_encoding:\n",
    "            encodings_to_try.insert(0, detected_encoding)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for encoding in encodings_to_try:\n",
    "        try:\n",
    "            return pd.read_csv(file_path, encoding=encoding, **kwargs)\n",
    "        except (UnicodeDecodeError, UnicodeError):\n",
    "            continue\n",
    "\n",
    "    raise ValueError(f\"Could not read {file_path} with any of the tried encodings\")\n",
    "\n",
    "def standardize_columns(df, year):\n",
    "    \"\"\"Standardize column names based on the year and known patterns\"\"\"\n",
    "    # Convert all columns to lowercase first\n",
    "    df.columns = df.columns.str.lower()\n",
    "\n",
    "    # Drop OBJECTID and OID_ columns completely - we only want id_dmr\n",
    "    columns_to_drop = ['objectid', 'oid_']\n",
    "    df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Define the data directory and file names\n",
    "data_dir = r\"C:\\Users\\AGFirass\\PycharmProjects\\openDataParisDataScienceProject\\data\"\n",
    "files = [\n",
    "    \"DMR_2018.csv\",\n",
    "    \"DMR_2019.csv\",\n",
    "    \"DMR_2020.csv\",\n",
    "    \"DMR_2021.csv\",\n",
    "    \"DMR_2022.csv\",\n",
    "    \"DMR_2023.csv\"\n",
    "]\n",
    "\n",
    "def find_common_columns(file_paths):\n",
    "    \"\"\"Find columns that are common to all CSV files after standardization\"\"\"\n",
    "    all_columns = []\n",
    "\n",
    "    # Read headers from each file and standardize\n",
    "    for file_path in file_paths:\n",
    "        df = read_csv_safe(file_path, nrows=0, sep=';')\n",
    "        year = int(os.path.basename(file_path).split('_')[1].split('.')[0])\n",
    "        df = standardize_columns(df, year)\n",
    "        columns = set(df.columns)\n",
    "        all_columns.append(columns)\n",
    "        print(f\"{os.path.basename(file_path)}: {sorted(list(columns))}\")\n",
    "\n",
    "    # Find intersection of all column sets\n",
    "    common_columns = reduce(lambda x, y: x.intersection(y), all_columns)\n",
    "    print(f\"\\nCommon columns across all files: {len(common_columns)}\")\n",
    "    print(\"Common columns:\", sorted(list(common_columns)))\n",
    "\n",
    "    return list(common_columns)\n",
    "\n",
    "def merge_csv_files(file_paths, common_columns):\n",
    "    \"\"\"Merge CSV files using only common columns\"\"\"\n",
    "    dataframes = []\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        print(f\"Reading {os.path.basename(file_path)}...\")\n",
    "\n",
    "        # Read the full CSV file\n",
    "        df = read_csv_safe(file_path, sep=';')\n",
    "\n",
    "        # Get year for standardization\n",
    "        year = int(os.path.basename(file_path).split('_')[1].split('.')[0])\n",
    "\n",
    "        # Standardize column names\n",
    "        df = standardize_columns(df, year)\n",
    "\n",
    "        # Select only common columns\n",
    "        df = df[common_columns]\n",
    "\n",
    "        # Add a year column for identification\n",
    "        df['year'] = year\n",
    "\n",
    "        dataframes.append(df)\n",
    "        print(f\"  Shape: {df.shape}\")\n",
    "\n",
    "    # Concatenate all dataframes\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "    print(f\"\\nMerged dataframe shape: {merged_df.shape}\")\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Create full file paths\n",
    "    file_paths = [os.path.join(data_dir, file) for file in files]\n",
    "\n",
    "    # Check if all files exist\n",
    "    missing_files = [f for f in file_paths if not os.path.exists(f)]\n",
    "    if missing_files:\n",
    "        print(\"Missing files:\")\n",
    "        for f in missing_files:\n",
    "            print(f\"  {f}\")\n",
    "        exit(1)\n",
    "\n",
    "    # Find common columns\n",
    "    common_columns = find_common_columns(file_paths)\n",
    "\n",
    "    if not common_columns:\n",
    "        print(\"No common columns found across all files!\")\n",
    "        exit(1)\n",
    "\n",
    "    # Merge the files\n",
    "    merged_df = merge_csv_files(file_paths, common_columns)\n",
    "\n",
    "    # Display info about the merged dataframe\n",
    "    print(f\"\\nMerged dataframe info:\")\n",
    "    print(f\"Shape: {merged_df.shape}\")\n",
    "    print(f\"Columns: {list(merged_df.columns)}\")\n",
    "    print(f\"Year distribution:\")\n",
    "    print(merged_df['year'].value_counts().sort_index())\n",
    "\n",
    "    # Save the merged dataframe\n",
    "    output_file = os.path.join(data_dir, \"DMR_merged_2018_2023.csv\")\n",
    "    merged_df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nMerged data saved to: {output_file}\")\n",
    "\n",
    "    # Show sample of the data\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(merged_df.head())\n",
    "\n",
    "    # Show data types\n",
    "    print(f\"\\nData types:\")\n",
    "    print(merged_df.dtypes)"
   ],
   "id": "f24115ee2cc3d0d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DMR_2018.csv: ['adresse', 'anneedecl', 'arrondissement', 'code_postal', 'conseilquartier', 'datedecl', 'id_dmr', 'intervenant', 'moisdecl', 'numero', 'prefixe', 'soustype', 'type', 'ville', 'x', 'y']\n",
      "DMR_2019.csv: ['adresse', 'anneedecl', 'arrondissement', 'code_postal', 'conseilquartier', 'datedecl', 'id_dmr', 'intervenant', 'moisdecl', 'numero', 'prefixe', 'soustype', 'type', 'ville', 'x', 'y']\n",
      "DMR_2020.csv: ['adresse', 'anneedecl', 'arrondissement', 'code_postal', 'conseilquartier', 'datedecl', 'id_dmr', 'intervenant', 'moisdecl', 'numero', 'prefixe', 'soustype', 'type', 'ville', 'x', 'y']\n",
      "DMR_2021.csv: ['adresse', 'anneedecl', 'arrondissement', 'code_postal', 'conseilquartier', 'datedecl', 'dateetat', 'etat', 'id_dmr', 'intervenant', 'moisdecl', 'numero', 'prefixe', 'soustype', 'type', 'ville', 'x', 'y']\n",
      "DMR_2022.csv: ['adresse', 'anneedecl', 'arrondissement', 'code_postal', 'conseilquartier', 'datedecl', 'dateetat', 'etat', 'id_dmr', 'intervenant', 'moisdecl', 'numero', 'prefixe', 'soustype', 'type', 'ville', 'x', 'y']\n",
      "DMR_2023.csv: ['adresse', 'anneedecl', 'arrondissement', 'code_postal', 'conseilquartier', 'datedecl', 'dateetat', 'etat', 'id_dmr', 'intervenant', 'moisdecl', 'numero', 'prefixe', 'soustype', 'type', 'ville', 'x', 'y']\n",
      "\n",
      "Common columns across all files: 16\n",
      "Common columns: ['adresse', 'anneedecl', 'arrondissement', 'code_postal', 'conseilquartier', 'datedecl', 'id_dmr', 'intervenant', 'moisdecl', 'numero', 'prefixe', 'soustype', 'type', 'ville', 'x', 'y']\n",
      "Reading DMR_2018.csv...\n",
      "  Shape: (251692, 17)\n",
      "Reading DMR_2019.csv...\n",
      "  Shape: (556643, 17)\n",
      "Reading DMR_2020.csv...\n",
      "  Shape: (586270, 17)\n",
      "Reading DMR_2021.csv...\n",
      "  Shape: (850304, 17)\n",
      "Reading DMR_2022.csv...\n",
      "  Shape: (846239, 17)\n",
      "Reading DMR_2023.csv...\n",
      "  Shape: (862981, 17)\n",
      "\n",
      "Merged dataframe shape: (3954129, 17)\n",
      "\n",
      "Merged dataframe info:\n",
      "Shape: (3954129, 17)\n",
      "Columns: ['id_dmr', 'type', 'ville', 'x', 'y', 'soustype', 'prefixe', 'datedecl', 'numero', 'moisdecl', 'code_postal', 'intervenant', 'adresse', 'arrondissement', 'conseilquartier', 'anneedecl', 'year']\n",
      "Year distribution:\n",
      "year\n",
      "2018    251692\n",
      "2019    556643\n",
      "2020    586270\n",
      "2021    850304\n",
      "2022    846239\n",
      "2023    862981\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Merged data saved to: C:\\Users\\AGFirass\\PycharmProjects\\openDataParisDataScienceProject\\data\\DMR_merged_2018_2023.csv\n",
      "\n",
      "First few rows:\n",
      "         id_dmr                                       type     ville  \\\n",
      "0  A2018A000001                          Mobiliers urbains   Paris 9   \n",
      "1  S2018A000002                          Objets abandonnÃ©s  Paris 15   \n",
      "2  S2018A000003  Graffitis, tags, affiches et autocollants  Paris 15   \n",
      "3  G2018A000004                    Ã‰clairage / Ã‰lectricitÃ©   Paris 4   \n",
      "4  G2018A000005                          Objets abandonnÃ©s  Paris 18   \n",
      "\n",
      "             x            y  \\\n",
      "0  2,336608406    48,881588   \n",
      "1  2,294903576  48,84168304   \n",
      "2  2,295035066  48,84117406   \n",
      "3  2,368076605     48,85348   \n",
      "4  2,354395399    48,887924   \n",
      "\n",
      "                                            soustype prefixe  \\\n",
      "0  Protection:Potelet, barriÃ¨re ou garde-corps dÃ©...       A   \n",
      "1               Autres objets encombrants abandonnÃ©s       S   \n",
      "2            Graffitis sur mur, faÃ§ade sur rue, pont       S   \n",
      "3  Fils Ã©lectriques apparents sur lampadaire ou s...       G   \n",
      "4               Autres objets encombrants abandonnÃ©s       G   \n",
      "\n",
      "             datedecl numero  moisdecl code_postal  \\\n",
      "0  2018-01-01 0:00:00      1         1       75009   \n",
      "1  2018-01-01 0:00:00      2         1       75015   \n",
      "2  2018-01-01 0:00:00      3         1       75015   \n",
      "3  2018-01-01 0:00:00      4         1       75004   \n",
      "4  2018-01-01 0:00:00      5         1       75018   \n",
      "\n",
      "                                  intervenant  \\\n",
      "0                                        SMEP   \n",
      "1  Ramen en tant que prestataire de DansMaRue   \n",
      "2                                   graffitis   \n",
      "3                             EVESA_ToutParis   \n",
      "4  Ramen en tant que prestataire de DansMaRue   \n",
      "\n",
      "                                        adresse arrondissement  \\\n",
      "0  67-69 rue jean-baptiste pigalle, 75009 PARIS              9   \n",
      "1          29 rue de l'abbÃ© groult, 75015 PARIS             15   \n",
      "2          40 rue de l'abbÃ© groult, 75015 PARIS             15   \n",
      "3              2 rue saint-antoine, 75004 PARIS              4   \n",
      "4               24 rue de laghouat, 75018 PARIS             18   \n",
      "\n",
      "               conseilquartier  anneedecl  year  \n",
      "0            BLANCHE - TRINITE       2018  2018  \n",
      "1              SAINT - LAMBERT       2018  2018  \n",
      "2              SAINT - LAMBERT       2018  2018  \n",
      "3                      ARSENAL       2018  2018  \n",
      "4  GOUTTE D'OR - CHATEAU ROUGE       2018  2018  \n",
      "\n",
      "Data types:\n",
      "id_dmr             object\n",
      "type               object\n",
      "ville              object\n",
      "x                  object\n",
      "y                  object\n",
      "soustype           object\n",
      "prefixe            object\n",
      "datedecl           object\n",
      "numero             object\n",
      "moisdecl            int64\n",
      "code_postal        object\n",
      "intervenant        object\n",
      "adresse            object\n",
      "arrondissement     object\n",
      "conseilquartier    object\n",
      "anneedecl           int64\n",
      "year                int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T21:26:51.645967Z",
     "start_time": "2025-09-14T21:26:35.744768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_DMR = r\"C:\\Users\\AGFirass\\PycharmProjects\\openDataParisDataScienceProject\\data\\DMR_merged_2018_2023.csv\"\n",
    "df_DMR = pd.read_csv(final_DMR)\n",
    "df_DMR.head()"
   ],
   "id": "4f66f6f66a5afa1f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AGFirass\\AppData\\Local\\Temp\\ipykernel_9020\\2813147102.py:2: DtypeWarning: Columns (8,10,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_DMR = pd.read_csv(final_DMR)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         id_dmr                                       type     ville  \\\n",
       "0  A2018A000001                          Mobiliers urbains   Paris 9   \n",
       "1  S2018A000002                          Objets abandonnÃ©s  Paris 15   \n",
       "2  S2018A000003  Graffitis, tags, affiches et autocollants  Paris 15   \n",
       "3  G2018A000004                    Ã‰clairage / Ã‰lectricitÃ©   Paris 4   \n",
       "4  G2018A000005                          Objets abandonnÃ©s  Paris 18   \n",
       "\n",
       "             x            y  \\\n",
       "0  2,336608406    48,881588   \n",
       "1  2,294903576  48,84168304   \n",
       "2  2,295035066  48,84117406   \n",
       "3  2,368076605     48,85348   \n",
       "4  2,354395399    48,887924   \n",
       "\n",
       "                                            soustype prefixe  \\\n",
       "0  Protection:Potelet, barriÃ¨re ou garde-corps dÃ©...       A   \n",
       "1               Autres objets encombrants abandonnÃ©s       S   \n",
       "2            Graffitis sur mur, faÃ§ade sur rue, pont       S   \n",
       "3  Fils Ã©lectriques apparents sur lampadaire ou s...       G   \n",
       "4               Autres objets encombrants abandonnÃ©s       G   \n",
       "\n",
       "             datedecl numero  moisdecl code_postal  \\\n",
       "0  2018-01-01 0:00:00      1         1       75009   \n",
       "1  2018-01-01 0:00:00      2         1       75015   \n",
       "2  2018-01-01 0:00:00      3         1       75015   \n",
       "3  2018-01-01 0:00:00      4         1       75004   \n",
       "4  2018-01-01 0:00:00      5         1       75018   \n",
       "\n",
       "                                  intervenant  \\\n",
       "0                                        SMEP   \n",
       "1  Ramen en tant que prestataire de DansMaRue   \n",
       "2                                   graffitis   \n",
       "3                             EVESA_ToutParis   \n",
       "4  Ramen en tant que prestataire de DansMaRue   \n",
       "\n",
       "                                        adresse arrondissement  \\\n",
       "0  67-69 rue jean-baptiste pigalle, 75009 PARIS              9   \n",
       "1          29 rue de l'abbÃ© groult, 75015 PARIS             15   \n",
       "2          40 rue de l'abbÃ© groult, 75015 PARIS             15   \n",
       "3              2 rue saint-antoine, 75004 PARIS              4   \n",
       "4               24 rue de laghouat, 75018 PARIS             18   \n",
       "\n",
       "               conseilquartier  anneedecl  year  \n",
       "0            BLANCHE - TRINITE       2018  2018  \n",
       "1              SAINT - LAMBERT       2018  2018  \n",
       "2              SAINT - LAMBERT       2018  2018  \n",
       "3                      ARSENAL       2018  2018  \n",
       "4  GOUTTE D'OR - CHATEAU ROUGE       2018  2018  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_dmr</th>\n",
       "      <th>type</th>\n",
       "      <th>ville</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>soustype</th>\n",
       "      <th>prefixe</th>\n",
       "      <th>datedecl</th>\n",
       "      <th>numero</th>\n",
       "      <th>moisdecl</th>\n",
       "      <th>code_postal</th>\n",
       "      <th>intervenant</th>\n",
       "      <th>adresse</th>\n",
       "      <th>arrondissement</th>\n",
       "      <th>conseilquartier</th>\n",
       "      <th>anneedecl</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2018A000001</td>\n",
       "      <td>Mobiliers urbains</td>\n",
       "      <td>Paris 9</td>\n",
       "      <td>2,336608406</td>\n",
       "      <td>48,881588</td>\n",
       "      <td>Protection:Potelet, barriÃ¨re ou garde-corps dÃ©...</td>\n",
       "      <td>A</td>\n",
       "      <td>2018-01-01 0:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>75009</td>\n",
       "      <td>SMEP</td>\n",
       "      <td>67-69 rue jean-baptiste pigalle, 75009 PARIS</td>\n",
       "      <td>9</td>\n",
       "      <td>BLANCHE - TRINITE</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S2018A000002</td>\n",
       "      <td>Objets abandonnÃ©s</td>\n",
       "      <td>Paris 15</td>\n",
       "      <td>2,294903576</td>\n",
       "      <td>48,84168304</td>\n",
       "      <td>Autres objets encombrants abandonnÃ©s</td>\n",
       "      <td>S</td>\n",
       "      <td>2018-01-01 0:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>75015</td>\n",
       "      <td>Ramen en tant que prestataire de DansMaRue</td>\n",
       "      <td>29 rue de l'abbÃ© groult, 75015 PARIS</td>\n",
       "      <td>15</td>\n",
       "      <td>SAINT - LAMBERT</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S2018A000003</td>\n",
       "      <td>Graffitis, tags, affiches et autocollants</td>\n",
       "      <td>Paris 15</td>\n",
       "      <td>2,295035066</td>\n",
       "      <td>48,84117406</td>\n",
       "      <td>Graffitis sur mur, faÃ§ade sur rue, pont</td>\n",
       "      <td>S</td>\n",
       "      <td>2018-01-01 0:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>75015</td>\n",
       "      <td>graffitis</td>\n",
       "      <td>40 rue de l'abbÃ© groult, 75015 PARIS</td>\n",
       "      <td>15</td>\n",
       "      <td>SAINT - LAMBERT</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G2018A000004</td>\n",
       "      <td>Ã‰clairage / Ã‰lectricitÃ©</td>\n",
       "      <td>Paris 4</td>\n",
       "      <td>2,368076605</td>\n",
       "      <td>48,85348</td>\n",
       "      <td>Fils Ã©lectriques apparents sur lampadaire ou s...</td>\n",
       "      <td>G</td>\n",
       "      <td>2018-01-01 0:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>75004</td>\n",
       "      <td>EVESA_ToutParis</td>\n",
       "      <td>2 rue saint-antoine, 75004 PARIS</td>\n",
       "      <td>4</td>\n",
       "      <td>ARSENAL</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G2018A000005</td>\n",
       "      <td>Objets abandonnÃ©s</td>\n",
       "      <td>Paris 18</td>\n",
       "      <td>2,354395399</td>\n",
       "      <td>48,887924</td>\n",
       "      <td>Autres objets encombrants abandonnÃ©s</td>\n",
       "      <td>G</td>\n",
       "      <td>2018-01-01 0:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>75018</td>\n",
       "      <td>Ramen en tant que prestataire de DansMaRue</td>\n",
       "      <td>24 rue de laghouat, 75018 PARIS</td>\n",
       "      <td>18</td>\n",
       "      <td>GOUTTE D'OR - CHATEAU ROUGE</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T21:27:26.081893Z",
     "start_time": "2025-09-14T21:27:26.033804Z"
    }
   },
   "cell_type": "code",
   "source": "df_DMR.anneedecl.unique()",
   "id": "312d5112181f88fe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2018, 2019, 2020, 2021, 2022, 2023])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T21:41:05.439871Z",
     "start_time": "2025-09-14T21:41:05.419743Z"
    }
   },
   "cell_type": "code",
   "source": "df_DMR.shape",
   "id": "f78e3477a301075b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3954129, 17)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T22:07:18.328838Z",
     "start_time": "2025-09-14T22:02:41.114577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "csv_file = r\"C:/Users/AGFirass/PycharmProjects/openDataParisDataScienceProject/data/DMR_merged_2018_2023.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_file, sep=',')\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://root:001291100@localhost/open_data_paris\")\n",
    "\n",
    "df.to_sql('dmr', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"CSV uploaded to MySQL successfully!\")"
   ],
   "id": "295f2141d285f761",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AGFirass\\AppData\\Local\\Temp\\ipykernel_9020\\786604253.py:5: DtypeWarning: Columns (8,10,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file, sep=',')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id_dmr', 'type', 'ville', 'x', 'y', 'soustype', 'prefixe', 'datedecl',\n",
      "       'numero', 'moisdecl', 'code_postal', 'intervenant', 'adresse',\n",
      "       'arrondissement', 'conseilquartier', 'anneedecl', 'year'],\n",
      "      dtype='object')\n",
      "CSV uploaded to MySQL successfully!\n"
     ]
    }
   ],
   "execution_count": 73
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
